# OKR Analysis MCP Server ğŸš€

A powerful Model Context Protocol (MCP) server for analyzing OKR (Objectives and Key Results) data. Built with `fastmcp`, this server allows AI assistants like ChatGPT to access, analyze, and report on your organization's OKR progress.

## âœ¨ Features

- **ğŸŒ³ Visual Tree**: Generates hierarchical OKR trees with clear visualization.
- **ğŸ“ Form Data Extraction**: Automatically extracts custom fields (e.g., Priority, Contribution) from Targets.
- **ğŸ¤– AI Ready**: Designed for integration with ChatGPT via MCP.
- **âš¡ Robust Sync**: Includes auto-retry logic and incremental sync capabilities.

## ğŸ› ï¸ Prerequisites

- Python 3.10+
- [ngrok](https://ngrok.com/) (For manual deployment)
- Base.vn API Tokens

## ğŸ“¦ Local Installation

1. **Clone the repository:**
   ```bash
   git clone https://github.com/xnk3-aplus/mcp-test.git
   cd mcp-test
   ```

2. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

3. **Configure Tokens:**
   Create a `.env` file in the root directory (based on `.env.example` if available) and add your Base.vn tokens:
   ```env
   GOAL_ACCESS_TOKEN=your_goal_token_here
   ACCOUNT_ACCESS_TOKEN=your_account_token_here
   TABLE_ACCESS_TOKEN=your_table_token_here
   WEWORK_ACCESS_TOKEN=your_wework_token_here
   ```

## ğŸš€ Deployment Options

You can deploy this server in two ways:
1. **â˜ï¸ FastMCP Cloud** (Recommended for easiest hosting)
2. **ğŸ”Œ ChatGPT via Ngrok** (Manual local tunnel)

---

### Option 1: FastMCP Cloud â˜ï¸
*The fastest way to deploy your server securely.*

1. **Push to GitHub**: Ensure your code is in a GitHub repository.
2. **Go to [fastmcp.cloud](https://fastmcp.cloud)** and log in with GitHub.
3. **Create Project**:
   - Select your repository.
   - Entrypoint: `server.py:mcp`
4. **Deploy**: Click Deploy. You get a secure URL (e.g., `https://okr-server.fastmcp.app/mcp`).
5. **Connect**: Use this URL in your MCP client (e.g., ChatGPT, Cursor).

---

### Option 2: ChatGPT via Ngrok ğŸ”Œ
*For local development or direct connection to ChatGPT.*

#### 1. Start Local Server
```bash
python server.py
```
*Runs on `http://localhost:8000`*

#### 2. Expose via Ngrok
```bash
ngrok http 8000
```
*Copy your public https URL (e.g., `https://abc-123.ngrok-free.app`).*

#### 3. Connect to ChatGPT
1. **Enable Developer Mode**:
   - Go to **ChatGPT Settings** â†’ **Connectors** â†’ **Advanced** â†’ Enable **Developer Mode**.
2. **Create Connector**:
   - Click **Create** (top right).
   - **Name**: `OKR Analysis Server`
   - **Server URL**: Paste your ngrok URL (`https://abc-123.ngrok-free.app/mcp/`).
   - Click **Create** and **Trust**.
3. **Use in Chat**:
   - New Chat â†’ Click **+** â†’ **More** â†’ **Developer Mode**.
   - Toggle **OKR Analysis Server** ON.

---

## ğŸ“ API Reference

| Tool | Description | Tags | Auto-Run |
|------|-------------|------|----------|
| `get_all_checkins` | Láº¥y danh sÃ¡ch check-in chi tiáº¿t (TÃªn, NgÃ y, User, KR, Next Action, Value). | `okr`, `checkin`, `report` | âœ… Yes |
| `checkin_kr` | Táº¡o check-in má»›i cho Key Result. Inputs: username, kr_id, value, done_work_text (1-2 cÃ¢u), next_plan_text (1-2 cÃ¢u), confidence. Date tá»± Ä‘á»™ng láº¥y ngÃ y hiá»‡n táº¡i. | `okr`, `write`, `checkin` | âŒ No |
| `get_okr_tree` | Láº¥y cÃ¢y má»¥c tiÃªu OKR. **Param:** `cycle` (optional) - TÃªn chu ká»³ hoáº·c thá»i gian (e.g. "2024-11"). Default: Current. | `okr`, `tree`, `visualization` | âœ… Yes |
| `review_user_work_plus` | Tá»•ng há»£p cÃ´ng viá»‡c WeWork (30 ngÃ y) vÃ  OKR Check-ins cá»§a má»™t ngÆ°á»i dÃ¹ng. Há»— trá»£ tÃ¬m theo Username hoáº·c Real Name. | `user`, `wework`, `okr` | âœ… Yes |

## ğŸ“„ License
MIT License